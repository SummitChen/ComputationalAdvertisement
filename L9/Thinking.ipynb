{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***1. 排序模型按照样本生成方法和损失函数的不同，可以划分成Pointwise, Pairwise, Listwise三类方法，这三类排序方法有何区别？***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这三种方法的主要区别如下：\n",
    "\n",
    "- Pointwise\n",
    "    - 针对单一文档的排序策略\n",
    "    - 每个训练样本独立构建，例如$（V_1,V_2...V_n，Y),$ $V$是特征，$Y$是label。\n",
    "    - 损失函数是最小化预测值与真实Label之间的差值。\n",
    "    - 本质上将排序任务转换成为回归任务，可通过回归模型进行求解例如LR, GBDT, Prank 和 McRank\n",
    "    \n",
    "- Pairwise\n",
    "    - 关注两两文档的顺序关系的排序策略\n",
    "    - 样本构建为$(V^1_{(n)}, V^2_{(n)}, Y), V^1_{(n)}, V^2_{(n)}$分别是两个文档的特征，$Y$是label通常的形式为$\\{-1, 1\\}$或$\\{1, -1\\}$用来标识两文档的先后顺序。\n",
    "    - 损失函数为Pairwise分类Loss\n",
    "    - 主要算法有SVM Rank, RankBoost, RankNet等\n",
    "    \n",
    "- Listwise\n",
    "    - 将一次Query对应的所有搜索结果列表作为一个训练样本\n",
    "    - 每个样本为文档集合作为输入的特征，而集合中文档的打分和排序列表作为输出。\n",
    "    - 损失函数有NDCG(Normalized Discounted Cumulative Gain), MAP(Mean Average Precision)\n",
    "    - 主要算法有ListNet, AdaRank, SoftRank, LambdaRank, LambdaMART等\n",
    "    \n",
    "下面的图示，展示了不同的策略是如何构建样本以及结果的验证的。\n",
    "\n",
    "![](images/Three-wises.png)\n",
    "\n",
    "<center>***Figure1*** - three-wises</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***2. 排序模型按照结构划分，可以分为线性排序模型、树模型、深度学习模型，这些模型都有哪些典型的代表？***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 线性排序模型的代表有：LR, 以及引入自动二阶交叉特征的FM和FFM。 \n",
    "- 非线性模型的代表有：树模型GBDT 和 GBDT + LR。\n",
    "- 深度模型的代表有：Wide&Deep, DeepFM, NFM等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***3. NDCG如何计算？***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDCG (Normalized Discounted Cumulative Gain) 规范化的折损累计增益，是由折损累计增益（DCG）除以理想情况下的最大累计增益（IDCG）。例如通过如下公式计算前$p$个排序结果的NDCG\n",
    "$$NDCG_p = \\frac{DCG_p}{IDCG_p}$$\n",
    "\n",
    "DCG（Discounted CG）折损收益，是在一个收益（相关性大小）的结果上除以一个折损值，然后将这些值累积起来。公式表示为：\n",
    "$$DCG_p= \\sum^{p}_{i=1}{\\frac{rel_i}{log_2{(i+1)}}}$$\n",
    "其中$p$表示前$p$个排序结果，$i$表示第$i$个位置，$rel_i$表示的是在第$i$位置上得到的相关性大小；$\\frac{rel_i}{log_2{(i+1)}}$表示的就是在第$i$位置上产生的收益。\n",
    "\n",
    "IDCG（Ideal DCG）理想情况下的最大收益：\n",
    "$$IDCG_p = \\sum^{|REL|_p}_{i=1}{\\frac{rel_i}{log_2{(i+1)}}}$$\n",
    "\n",
    "$|REL|_p$表示，所有结果按照相关性大小进行排序后取前$p$个值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***4. 搜索排序和推荐系统的相同和不同之处有哪些？***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搜索排序和推荐系统都是按照相关性大小给用户提供相关较高的前$K$个物品，在计算时通常可以采用相同的feature。不同之处主要体现在以下方面：\n",
    "- 推荐是发散的、无意识的主动推荐。相比搜索而言，排序的准确性不一定是最重要的，因为在这种情况下用户的需求有一定的随机性。\n",
    "- 推荐系统，采用 PointWise 的策略较多，预测出来的分数具有实际的物理意义，代表了目标用户点击item的预测概率。\n",
    "- 多样性和随机性也导致了推荐场景不适合用 PairWise 和 ListWise 的策略。\n",
    "- 搜索排序，是一种意识的被动推荐。系统是否能够将与用户搜索关键词和Profile最相关的item按照相关性顺序提供给用户是非常重要的。因此推荐的结果中物品的相关性顺序非常重要，所以通常采用PairWise 和 ListWise非常重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***5. Listwise排序模型能否应用到推荐系统中？***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ListWise排序是基于物品与用户相关性大小来进行的物品的排序，所以从理论上讲ListWise排序模型也能够应用到推荐系统中，用来将与用户最相关的物品排序后推荐给用户。但是推荐系统中用户的期望具有一定的发散性和随机性，因此ListWise策略从物理意义的角度考虑并不合理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf': conda)",
   "language": "python",
   "name": "python37664bittfconda946bd5c5de684c5d81ef2ce52df4450d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
