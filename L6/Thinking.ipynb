{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1. 在实际工作中，FM和MF哪个应用的更多，为什么?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FM（Factorization Machine）表示的因子分解机而MF(Matric Factorization)代表的是矩阵分解。MF在推荐系统中所能解决的特定问题是将User-Item评分矩阵中的已知值对矩阵进行分解，然后根据分解后的矩阵重新计算评分矩阵来实现预测。MF所能够利用的信息，只有User-Item的关系矩阵，而无法利用其它特征，比如时间特征。而FM矩阵将User和Item都进行了one-hot编码作为特征，使得特征维度非常巨大而且稀疏，引入了更多分辅助信息作为特征，并可根据特征与特征之间的关系进行预测。在FM计算二阶特征组合系数的时候，使用的MF技术来求解系数。\n",
    "- 此外MF还可以看做FM的一个特例。从应用场景的角度来讲，在现实世界中，我们往往会采集用户“评分”行为的多个维度的特征，所以从特征利用的角度来讲，FM比MF应用更加广泛。而且由于在推荐的过程考虑和计算了多个维度的特征，以及特征与特征之间的关系。FM比MF预测更加准确。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2. FFM与FM有哪些区别？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从字面意思上理解 FM （Factorization Machines）因子分解机而FFM（Field-aware Factorization Machines）可领域感知的因子分解机。顾名思义FFM就是在FM的基础上增加了领域感知功能。我们知道，FM在做计算和预测的时候考虑到了特征与特征之间的关系。但这里所表示的关系只是具体特征与具体特征的关系，比如特征A是用户购买的商品是电子设备，特征B是用户购买商品的价格是$20，那么在FM计算的时候只会考虑具体的这两个特征的关系。而FFM则会在计算这个两个特征的时候标注出来，特征A是与价格领域（Field）的特征B进行组合，而特征B是与商品类别领域（Field）的特征A进行组合。相当于人为的使得算法具有了感知领域信息的能力，而这种能力很难从数据中自动学习得到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *3. DeepFM相比于FM解决了哪些问题，原理是怎样的？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DeepFM在FM的基础上保留了FM的特性，并且突破了FM在有限的时间内只能计算最高二阶特征组合的限制，也就是DeepFM不仅可以考虑一阶和二阶特征，它还可以计算更高阶的特征。\n",
    "- 总体来说，DeepFM设计了一个End-to-End模型结构，充分利用了深度学习特征抽取的优势，省去人为特征工程的步骤。具体来讲，DeepFM的数据输入层是稀疏的基于One-hot编码的一阶特征层，接下来数据进入Dense Embeddings层，将特征做embedding学习表示为相同的维度k，通过Dense Embeding 层后，在FM层计算一阶特征即原始特征相加以及二阶特征即过embedding后的向量两两内积。平行的在Deep层，每个embedding向量做级联，然后做多层的全连接，学习更深的特征。在最后的输出层，将FM层输出与Deep层输出进行级联，接一个Dense层，作为最终输出结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *4. 假设一个小说网站，有N部小说，每部小说都有摘要描述。如何针对该网站制定基于内容的推荐系统，即用户看了某部小说后，推荐其他相关的小说。原理和步骤是怎样的?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对每部小说的摘要进行特征提取\n",
    "    - N-Gram，提取N个连续字的集合，作为特征\n",
    "    - TF-IDF，生成TFIDF矩阵\n",
    "2. 计算文章摘要之间的相似度矩阵\n",
    "    - 比如采用余弦相似度来衡量\n",
    "3. 对于指定的文章，选择相似度最大的Top-K个文章进行输出和推荐。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *5. Word2Vec的应用场景有哪些？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Word2Vec 是Word Embedding的一个重要方法之一。它不仅能够将文本的稀疏One-hot表示，转换为更加紧凑，长度相同的向量，而且根据所选的训练集的不同，这种向量的表示还反映的词与词之间的相似关系。\n",
    "- 在NLP任务中，经常需要通过深度学习模型在学习，分类以及生成文本。这种基于向量的词表示，更加便于计算，而在推荐系统中，尤其是基于内容推荐的场景中，可以通过计算物品描述关键词与关键词之间的相似关系，来完成物品的推荐。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
