{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *ALS都有哪些应用场景?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ALS (Alternating Least Squares) 交替最小二乘法。在机器学习应用中，ALS特指使用交替最小二乘求解的一个推荐系统算法。在推荐系统中，主要用来分解关系矩阵，是User-item协同过滤算法的一种。ALS通过现有矩阵中的数据经过最小二乘计算将User和Item分别于隐含特征的关系估计出来，然后再将隐含特征值引入计算来还原用户与物品关系矩阵。最后根据估计出的新值来进行推荐。\n",
    "\n",
    "  ALS 可应用于大多数基于User-Item 协同过滤的推荐场景，但同时因为是基于评分矩阵进行预测和推荐，所以也面临着冷启动的问题。而且由于计算效率的问题，不适用于数据量巨大的场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *ALS进行矩阵分解的时候，为什么可以并行化处理？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS的基本计算过程是交替地固定X或Y其中一项，并同时更新另外一项。在每一次更新的过程中，都可以单独的求解损失函数在某一方向上或者说在这一项某一行上的极限值。所以对X或Y的求解，就拆分成对每一行的求解并分布到多个的计算核中并行计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *梯度下降法中的批量梯度下降（BGD），随机梯度下降（SGD），和小批量梯度下降有什么区别（MBGD）*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这三者的区别在于每一次在梯度方向上的下降所参与计算的训练样本的个数。其中，随机梯度下降每一次只计算一个训练样本，批量梯度下降是在完成了对所有训练样本的计算之后才进行一次下降，小批量梯度下降每一次所计算的样本个数介于BGD和SGD之间的某个值，通常采用的值有16，32， 64 和 128."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *对数据进行可视化EDA都有哪些方式，你都是用过哪些工具？*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常用的可视化EDA有散点图，线图，柱状图，饼图，热力图，词云等。这些可视化方法可以帮助分析数据的统计学趋势，分布以及相互之间的关系。使用过的可视化工具有 matplotlib, seaborn和ggplot2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
