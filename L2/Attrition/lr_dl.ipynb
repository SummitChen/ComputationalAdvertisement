{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 294)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'Age', 'Attrition', 'BusinessTravel', 'DailyRate',\n",
       "       'Department', 'DistanceFromHome', 'Education', 'EducationField',\n",
       "       'EmployeeCount', 'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender',\n",
       "       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',\n",
       "       'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n",
       "       'NumCompaniesWorked', 'Over18', 'OverTime', 'PercentSalaryHike',\n",
       "       'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours',\n",
       "       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
       "       'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',\n",
       "       'YearsSinceLastPromotion', 'YearsWithCurrManager'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'user_id'\n",
    "target_col = 'Attrition'\n",
    "\n",
    "drop_cols = ['EmployeeCount', 'EmployeeNumber','StandardHours', 'Over18', 'MonthlyRate']\n",
    "\n",
    "digital_cols = ['MonthlyIncome', 'HourlyRate', 'MonthlyRate', 'DailyRate', 'PercentSalaryHike', 'YearsAtCompany',\n",
    "                'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "\n",
    "category_cols = ['BusinessTravel', 'Department', 'DistanceFromHome', 'Education', 'EducationField',\n",
    "                 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel',\n",
    "                'JobRole', 'JobSatisfaction', 'MaritalStatus', 'OverTime',\n",
    "                'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TrainingTimesLastYear',\n",
    "                'WorkLifeBalance', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col name:BusinessTravel                \tunique cate num in train:    3\tunique cate num in train:    3\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:Department                    \tunique cate num in train:    3\tunique cate num in train:    3\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:DistanceFromHome              \tunique cate num in train:   29\tunique cate num in train:   29\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:Education                     \tunique cate num in train:    5\tunique cate num in train:    5\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:EducationField                \tunique cate num in train:    6\tunique cate num in train:    6\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:EnvironmentSatisfaction       \tunique cate num in train:    4\tunique cate num in train:    4\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:Gender                        \tunique cate num in train:    2\tunique cate num in train:    2\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:JobInvolvement                \tunique cate num in train:    4\tunique cate num in train:    4\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:JobLevel                      \tunique cate num in train:    5\tunique cate num in train:    5\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:JobRole                       \tunique cate num in train:    9\tunique cate num in train:    9\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:JobSatisfaction               \tunique cate num in train:    4\tunique cate num in train:    4\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:MaritalStatus                 \tunique cate num in train:    3\tunique cate num in train:    3\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:OverTime                      \tunique cate num in train:    2\tunique cate num in train:    2\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:PerformanceRating             \tunique cate num in train:    2\tunique cate num in train:    2\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:RelationshipSatisfaction      \tunique cate num in train:    4\tunique cate num in train:    4\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:StockOptionLevel              \tunique cate num in train:    4\tunique cate num in train:    4\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:TrainingTimesLastYear         \tunique cate num in train:    7\tunique cate num in train:    7\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:WorkLifeBalance               \tunique cate num in train:    4\tunique cate num in train:    4\tnull sample in train:0.00\tnull sample in test:0.00\n",
      "Col name:Age                           \tunique cate num in train:   43\tunique cate num in train:   43\tnull sample in train:0.00\tnull sample in test:0.00\n"
     ]
    }
   ],
   "source": [
    "for col in category_cols:\n",
    "    nunique_tr = train[col].nunique()\n",
    "    nunique_te = test[col].nunique()\n",
    "    na_tr = len(train.loc[train[col].isna()]) / len(train)\n",
    "    na_te = len(test.loc[test[col].isna()]) / len(test)\n",
    "    print(f'Col name:{col:30}\\tunique cate num in train:{nunique_tr:5}\\tunique cate num in train:{nunique_te:5}\\tnull sample in train:{na_tr:.2f}\\tnull sample in test:{na_te:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col name:MonthlyIncome                 \n",
      "\tIn train data: min value:1009.00\tmax value:19999.00\tmean value:6458.69\tmedian value:4850.50\tstd value:4724.85\tnan sample rate:0.00\t\n",
      "\tIn  test data: min value:1514.00\tmax value:19740.00\tmean value:6679.89\tmedian value:5183.00\tstd value:4643.53\tnan sample rate:0.00\t\n",
      "Col name:HourlyRate                    \n",
      "\tIn train data: min value:30.00\tmax value:100.00\tmean value:65.13\tmedian value:65.00\tstd value:20.29\tnan sample rate:0.00\t\n",
      "\tIn  test data: min value:30.00\tmax value:100.00\tmean value:68.94\tmedian value:70.00\tstd value:20.22\tnan sample rate:0.00\t\n",
      "Col name:MonthlyRate                   \n",
      "\tIn train data: min value:2094.00\tmax value:26999.00\tmean value:14247.16\tmedian value:14225.50\tstd value:7133.77\tnan sample rate:0.00\t\n",
      "\tIn  test data: min value:2112.00\tmax value:26959.00\tmean value:14576.88\tmedian value:14309.00\tstd value:7059.40\tnan sample rate:0.00\t\n",
      "Col name:DailyRate                     \n",
      "\tIn train data: min value:104.00\tmax value:1499.00\tmean value:802.03\tmedian value:805.50\tstd value:405.95\tnan sample rate:0.00\t\n",
      "\tIn  test data: min value:102.00\tmax value:1496.00\tmean value:804.30\tmedian value:773.50\tstd value:394.28\tnan sample rate:0.00\t\n",
      "Col name:PercentSalaryHike             \n",
      "\tIn train data: min value:11.00\tmax value:25.00\tmean value:15.15\tmedian value:14.00\tstd value:3.65\tnan sample rate:0.00\t\n",
      "\tIn  test data: min value:11.00\tmax value:25.00\tmean value:15.44\tmedian value:14.00\tstd value:3.69\tnan sample rate:0.00\t\n",
      "Col name:YearsAtCompany                \n",
      "\tIn train data: min value:0.00\tmax value:40.00\tmean value:6.98\tmedian value:5.00\tstd value:6.09\tnan sample rate:0.00\t\n",
      "\tIn  test data: min value:0.00\tmax value:36.00\tmean value:7.11\tmedian value:5.00\tstd value:6.26\tnan sample rate:0.00\t\n",
      "Col name:YearsInCurrentRole            \n",
      "\tIn train data: min value:0.00\tmax value:18.00\tmean value:4.20\tmedian value:3.00\tstd value:3.63\tnan sample rate:0.00\t\n",
      "\tIn  test data: min value:0.00\tmax value:17.00\tmean value:4.35\tmedian value:3.00\tstd value:3.59\tnan sample rate:0.00\t\n",
      "Col name:YearsSinceLastPromotion       \n",
      "\tIn train data: min value:0.00\tmax value:15.00\tmean value:2.16\tmedian value:1.00\tstd value:3.21\tnan sample rate:0.00\t\n",
      "\tIn  test data: min value:0.00\tmax value:15.00\tmean value:2.30\tmedian value:1.00\tstd value:3.28\tnan sample rate:0.00\t\n",
      "Col name:YearsWithCurrManager          \n",
      "\tIn train data: min value:0.00\tmax value:17.00\tmean value:4.10\tmedian value:3.00\tstd value:3.56\tnan sample rate:0.00\t\n",
      "\tIn  test data: min value:0.00\tmax value:17.00\tmean value:4.22\tmedian value:3.00\tstd value:3.59\tnan sample rate:0.00\t\n"
     ]
    }
   ],
   "source": [
    "for col in digital_cols:\n",
    "    min_tr = train[col].min()\n",
    "    max_tr = train[col].max()\n",
    "    mean_tr = train[col].mean()\n",
    "    median_tr = train[col].median()\n",
    "    std_tr = train[col].std()\n",
    "    \n",
    "    min_te = test[col].min()\n",
    "    max_te = test[col].max()\n",
    "    mean_te = test[col].mean()\n",
    "    median_te = test[col].median()\n",
    "    std_te = test[col].std()\n",
    "    \n",
    "    na_tr = len(train.loc[train[col].isna()]) / len(train)\n",
    "    na_te = len(test.loc[test[col].isna()]) / len(test)\n",
    "    print(f'Col name:{col:30}')\n",
    "    print(f'\\tIn train data: min value:{min_tr:.2f}\\tmax value:{max_tr:.2f}\\tmean value:{mean_tr:.2f}\\tmedian value:{median_tr:.2f}\\tstd value:{std_tr:.2f}\\tnan sample rate:{na_tr:.2f}\\t')\n",
    "    print(f'\\tIn  test data: min value:{min_te:.2f}\\tmax value:{max_te:.2f}\\tmean value:{mean_te:.2f}\\tmedian value:{median_te:.2f}\\tstd value:{std_te:.2f}\\tnan sample rate:{na_te:.2f}\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[target_col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin data\n",
    "# Age\n",
    "age_bins = [0, 30, 40, 50, 60]\n",
    "age_labels = [1, 2, 3, 4]\n",
    "train['Age'] = pd.cut(train['Age'], age_bins, labels=age_labels).astype(int)\n",
    "test['Age'] = pd.cut(test['Age'], age_bins, labels=age_labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sacalar = MinMaxScaler()\n",
    "train_digital = sacalar.fit_transform(train[digital_cols])\n",
    "test_digital = sacalar.transform(test[digital_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(1, inplace=True)\n",
    "test.fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "train_category, test_category = None, None\n",
    "# drop_cols = ['EmployeeNumber', 'Over18', 'StandardHours']\n",
    "for col in [var for var in category_cols if var not in drop_cols]:\n",
    "    lbe, ohe = LabelEncoder(), OneHotEncoder()\n",
    "    \n",
    "    lbe.fit(pd.concat([train[col], test[col]]).values.reshape(-1, 1))\n",
    "    train[col] = lbe.transform(train[col])\n",
    "    test[col] = lbe.transform(test[col])\n",
    "    \n",
    "    ohe.fit(pd.concat([train[col], test[col]]).values.reshape(-1, 1))\n",
    "    oht_train = ohe.transform(train[col].values.reshape(-1, 1)).todense()\n",
    "    oht_test = ohe.transform(test[col].values.reshape(-1, 1)).todense()\n",
    "    \n",
    "    if train_category is None:\n",
    "        train_category = oht_train\n",
    "        test_category = oht_test\n",
    "    else:\n",
    "        train_category = np.hstack((train_category, oht_train))\n",
    "        test_category = np.hstack((test_category, oht_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1176, 9), (294, 9), (1176, 104), (294, 104))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_digital.shape, test_digital.shape, train_category.shape, test_category.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1176, 113), (294, 113))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = np.hstack((train_digital, train_category))\n",
    "test_features = np.hstack((test_digital, test_category))\n",
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col_dict = {'Yes': 1, 'No': 0}\n",
    "train_labels = train[target_col].map(target_col_dict).values\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 113)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                3648      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,989\n",
      "Trainable params: 3,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "dl_model = models.Sequential()\n",
    "dl_model.add(layers.Dense(units = 32, activation='relu', input_shape=(train_features.shape[1], )))\n",
    "dl_model.add(layers.Dense(units = 10, activation='relu'))\n",
    "dl_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "dl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 940 samples, validate on 236 samples\n",
      "Epoch 1/30\n",
      "940/940 [==============================] - 1s 946us/sample - loss: 0.5973 - AUC: 0.4761 - val_loss: 0.5358 - val_AUC: 0.4868\n",
      "Epoch 2/30\n",
      "940/940 [==============================] - 0s 57us/sample - loss: 0.4611 - AUC: 0.5193 - val_loss: 0.4953 - val_AUC: 0.5056\n",
      "Epoch 3/30\n",
      "940/940 [==============================] - 0s 53us/sample - loss: 0.4150 - AUC: 0.6276 - val_loss: 0.4851 - val_AUC: 0.5670\n",
      "Epoch 4/30\n",
      "940/940 [==============================] - 0s 52us/sample - loss: 0.3943 - AUC: 0.7189 - val_loss: 0.4720 - val_AUC: 0.6208\n",
      "Epoch 5/30\n",
      "940/940 [==============================] - 0s 52us/sample - loss: 0.3755 - AUC: 0.7827 - val_loss: 0.4562 - val_AUC: 0.6654\n",
      "Epoch 6/30\n",
      "940/940 [==============================] - 0s 54us/sample - loss: 0.3561 - AUC: 0.8242 - val_loss: 0.4413 - val_AUC: 0.7047\n",
      "Epoch 7/30\n",
      "940/940 [==============================] - 0s 56us/sample - loss: 0.3376 - AUC: 0.8509 - val_loss: 0.4324 - val_AUC: 0.7247\n",
      "Epoch 8/30\n",
      "940/940 [==============================] - 0s 54us/sample - loss: 0.3208 - AUC: 0.8673 - val_loss: 0.4222 - val_AUC: 0.7447\n",
      "Epoch 9/30\n",
      "940/940 [==============================] - 0s 55us/sample - loss: 0.3067 - AUC: 0.8766 - val_loss: 0.4133 - val_AUC: 0.7596\n",
      "Epoch 10/30\n",
      "940/940 [==============================] - 0s 55us/sample - loss: 0.2903 - AUC: 0.8914 - val_loss: 0.4060 - val_AUC: 0.7671\n",
      "Epoch 11/30\n",
      "940/940 [==============================] - 0s 56us/sample - loss: 0.2785 - AUC: 0.9001 - val_loss: 0.4071 - val_AUC: 0.7715\n",
      "Epoch 12/30\n",
      "940/940 [==============================] - 0s 52us/sample - loss: 0.2655 - AUC: 0.9095 - val_loss: 0.4024 - val_AUC: 0.7746\n",
      "Epoch 13/30\n",
      "940/940 [==============================] - 0s 51us/sample - loss: 0.2555 - AUC: 0.9135 - val_loss: 0.4030 - val_AUC: 0.7782\n",
      "Epoch 14/30\n",
      "940/940 [==============================] - 0s 53us/sample - loss: 0.2441 - AUC: 0.9202 - val_loss: 0.4014 - val_AUC: 0.7771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de57786a48>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['AUC'])\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_AUC', mode = 'max')\n",
    "\n",
    "dl_model.fit(train_features, train_labels,\n",
    "         batch_size=64,\n",
    "         epochs = 30,\n",
    "         validation_split=0.2,\n",
    "         callbacks=[early_stop]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.append(dl_model.predict(test_features)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(train_features, train_labels)\n",
    "predictions.append(lr_model.predict(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_result(x):\n",
    "    x = x if x <= 1.0 else 1.0\n",
    "    x = x if x >=0 else 0.0005\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test[['user_id']].copy()\n",
    "sub['Attrition'] = np.array(predictions).mean(axis=0)\n",
    "sub['Attrition'] = sub['Attrition'].apply(normal_result)\n",
    "sub.to_csv('submission_LR_DL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf': conda)",
   "language": "python",
   "name": "python37664bittfconda946bd5c5de684c5d81ef2ce52df4450d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
